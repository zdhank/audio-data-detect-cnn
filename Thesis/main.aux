\relax 
\@writefile{toc}{\contentsline {chapter}{Abstract}{2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Acknowledgment}{3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Contents}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{Abbreviations}{8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{sueur2012global}
\citation{soga2014land,wright2006uncertain}
\citation{green1979analysis}
\citation{seyfarth2003signalers}
\citation{stevenson2015general}
\@writefile{toc}{\contentsline {chapter}{Chapter\ \numberline {1.}{\ }Introduction}{9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Intro}{{1}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{9}}
\citation{kalan2015towards}
\citation{mellinger2007overview}
\citation{hill2018audiomoth}
\citation{kalan2015towards}
\citation{alldredge2007time}
\citation{Villanueva-RiveraLuisJ.2012PAWM}
\citation{digby2013practical}
\citation{sun2009classification}
\citation{lecun2015deep}
\citation{zhang2018survey}
\citation{chen2014big}
\citation{bao2018scalable}
\citation{xu2015discriminative}
\citation{parkhi2015deep}
\citation{lee2009unsupervised}
\citation{krizhevsky2012imagenet}
\citation{simonyan2014very}
\citation{43022}
\citation{girshick2015fast}
\citation{he2016deep}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Deep Learning on Audio data}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces General steps of deep learning on audio data\relax }}{12}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:pipline}{{1.1}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Data Collection}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Locations of Osa Peninsula in Costa Rica (provided by Jenna)\relax }}{13}}
\newlabel{fig:locations}{{1.2}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Aims and Organisation}{14}}
\citation{welch1967use}
\citation{davis1980comparison}
\@writefile{toc}{\contentsline {chapter}{Chapter\ \numberline {2.}{\ }Background}{15}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Audio Feature Extraction}{15}}
\citation{lippens2004comparison}
\citation{bedoya2014automatic}
\citation{choi2016automatic}
\citation{huzaifah2017comparison}
\citation{clemins2003application}
\citation{cakir2017convolutional}
\citation{le2011insect}
\citation{lippens2004comparison,le2011insect,clemins2003application}
\citation{rabiner1989tutorial}
\citation{trifa2008automated}
\citation{brown2009hidden}
\citation{zhao2017automated}
\citation{brown2009hidden}
\citation{clemins2003application,trifa2008automated,zhao2017automated}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Automated Recognition Models}{17}}
\citation{sercu2016very}
\citation{takahashi2016deep}
\citation{cakir2017convolutional}
\citation{8081512}
\citation{clemins2003application}
\citation{trifa2008automated}
\citation{brown2009hidden}
\citation{zhao2017automated}
\citation{le2011insect}
\citation{cakir2017convolutional}
\citation{cakir2017convolutional}
\citation{batdetect18}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Summary of models and feature extraction methods on species detection\relax }}{18}}
\newlabel{tabel:summarymodel}{{2.1}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Processing on Audio data}{18}}
\citation{aide2013real,batdetect18}
\citation{batdetect18}
\citation{batdetect18}
\citation{kim2002cepstrum}
\citation{nicolson2019deep}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Noise reduction of bat call}}{19}}
\newlabel{fig:batnoise}{{2.1}{19}}
\citation{takahashi2016deep}
\citation{sprengel2016audio}
\@writefile{toc}{\contentsline {chapter}{Chapter\ \numberline {3.}{\ }Methodology}{21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:method}{{3}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Mel-spectrogram Feature}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Compare of power spectrogram and log-magnitude spectrogram (example file: 5AEF815A.wav)\relax }}{22}}
\newlabel{fig:powerlog}{{3.1}{22}}
\citation{boll1979suppression}
\citation{ephraim1985speech}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Transformation of frequency-to-mel and mel filter banks\relax }}{23}}
\newlabel{fig:melscale}{{3.2}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Mel spectrogram\relax }}{24}}
\newlabel{fig:mel_spec}{{3.3}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Denoising Method}{24}}
\newlabel{eq:spectrum}{{3.6}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Spectral Subtraction}{25}}
\newlabel{sub-spec}{{3.7}{25}}
\citation{ephraim1985speech}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}MMSE Log-Spectral Amplitude Estimator}{26}}
\citation{ephraim1985speech}
\newlabel{eq:aa}{{3.13}{27}}
\newlabel{eq:magni}{{3.20}{27}}
\newlabel{eq:snr}{{3.21}{27}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces MMSE-LSA estimator for Python realisation\relax }}{28}}
\newlabel{alg:mmse}{{1}{28}}
\newlabel{fig:spec_sub}{{3.4a}{28}}
\newlabel{sub@fig:spec_sub}{{a}{28}}
\newlabel{fig:logmmse}{{3.4b}{28}}
\newlabel{sub@fig:logmmse}{{b}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Mel spectrogram by using noise reduction methods\relax }}{28}}
\newlabel{Fig:denoise}{{3.4}{28}}
\citation{sprengel2016audio}
\citation{schluter2015exploring}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Data Augmentation}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Design of CNN}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Activation Functions}{30}}
\citation{maas2013rectifier}
\newlabel{fig:sig}{{3.5a}{32}}
\newlabel{sub@fig:sig}{{a}{32}}
\newlabel{fig:relu}{{3.5b}{32}}
\newlabel{sub@fig:relu}{{b}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Different activation functions output curve\relax }}{32}}
\newlabel{Fig:act}{{3.5}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Layers of CNN}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces visualisation of convolutional filters in VGGNet\relax }}{33}}
\newlabel{fig:filter}{{3.6}{33}}
\citation{simard2003best}
\citation{kingma2014adam}
\citation{ruder2016overview}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Model Training}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Loss Functions and Optimizer}{34}}
\newlabel{eq:loss}{{3.27}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Hyperparameter Tuning}{35}}
\citation{felzenszwalb2009object}
\citation{girshick2014rich}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Training and validation loss curves of 100 training epochs\relax }}{36}}
\newlabel{fig:epoch}{{3.7}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Hard Negative Mining}{36}}
\newlabel{fig:10-4}{{3.8a}{37}}
\newlabel{sub@fig:10-4}{{a}{37}}
\newlabel{fig:10-5}{{3.8b}{37}}
\newlabel{sub@fig:10-5}{{b}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Training and validation loss curves of varying learning rate\relax }}{37}}
\newlabel{Fig:learning}{{3.8}{37}}
\newlabel{fig:pn}{{3.9a}{37}}
\newlabel{sub@fig:pn}{{a}{37}}
\newlabel{fig:hn}{{3.9b}{37}}
\newlabel{sub@fig:hn}{{b}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Hard negative mining examples in two-dimension\relax }}{37}}
\newlabel{Fig:hnm}{{3.9}{37}}
\@writefile{toc}{\contentsline {chapter}{Chapter\ \numberline {4.}{\ }Implementation and Results}{39}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{4}{39}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Dataset Compiling and Feature Extraction}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Data preparation}{39}}
\citation{crump2017designing}
\citation{batdetect18}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Number of Positive files in different types\relax }}{40}}
\newlabel{tabel:Positives}{{4.1}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Data processing}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Baseline Model}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Architecture}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Architecture of the baseline CNN\relax }}{42}}
\newlabel{fig:baseline}{{4.1}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Results}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Scores of balanced and unbalanced dataset with/without normalization\relax }}{43}}
\newlabel{tab:balanc}{{4.2}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Metrics scores of baseline model with data processing methods\relax }}{44}}
\newlabel{tabel:base dataset}{{4.3}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Histograms of baseline model: comparing 7 different strategies in accuracy, F1, recall and precision\relax }}{45}}
\newlabel{Fig:hist}{{4.2}{45}}
\citation{simonyan2014very}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}VGG-based Model}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Architecture of VGG-based CNN\relax }}{47}}
\newlabel{fig:vgg}{{4.3}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Architecture}{47}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Comparing depth of models\relax }}{48}}
\newlabel{tab:struc}{{4.4}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Results}{48}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Metrics score of Complex VGG-like model with three dataset strategies\relax }}{49}}
\newlabel{tabel:VGG dataset}{{4.5}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Histograms of VGG-based model: comparing 7 different strategies in accuracy, F1, recall and precision\relax }}{50}}
\newlabel{Fig:histvgg}{{4.4}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Position Detection on New Testing Data}{51}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Wrong predicted positions of two models\relax }}{51}}
\newlabel{tab:wrong pos}{{4.6}{51}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Comparison of Optimal Models}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Accuracy and loss curves for optimal baseline (LSA: Initial) and VGG-based models (Aug: hnm) with epoch=50, batch\_size=16, lr=$10^{-5}$\relax }}{53}}
\newlabel{Fig:curve}{{4.5}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Types of positives and negatives with easy and hard examples\relax }}{54}}
\newlabel{Fig:type}{{4.6}{54}}
\@writefile{toc}{\contentsline {chapter}{Chapter\ \numberline {5.}{\ }Conclusion}{55}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Conclusion}{{5}{55}}
\citation{hermans2017defense}
\@writefile{toc}{\contentsline {chapter}{Chapter\ \numberline {6.}{\ }Future Works}{57}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Future}{{6}{57}}
\citation{park2019specaugment}
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{sueur2012global}{1}
\bibcite{soga2014land}{2}
\bibcite{wright2006uncertain}{3}
\bibcite{green1979analysis}{4}
\bibcite{seyfarth2003signalers}{5}
\bibcite{stevenson2015general}{6}
\bibcite{kalan2015towards}{7}
\bibcite{mellinger2007overview}{8}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{59}}
\bibcite{hill2018audiomoth}{9}
\bibcite{alldredge2007time}{10}
\bibcite{Villanueva-RiveraLuisJ.2012PAWM}{11}
\bibcite{digby2013practical}{12}
\bibcite{sun2009classification}{13}
\bibcite{lecun2015deep}{14}
\bibcite{zhang2018survey}{15}
\bibcite{chen2014big}{16}
\bibcite{bao2018scalable}{17}
\bibcite{xu2015discriminative}{18}
\bibcite{parkhi2015deep}{19}
\bibcite{lee2009unsupervised}{20}
\bibcite{krizhevsky2012imagenet}{21}
\bibcite{simonyan2014very}{22}
\bibcite{43022}{23}
\bibcite{girshick2015fast}{24}
\bibcite{he2016deep}{25}
\bibcite{welch1967use}{26}
\bibcite{davis1980comparison}{27}
\bibcite{lippens2004comparison}{28}
\bibcite{bedoya2014automatic}{29}
\bibcite{choi2016automatic}{30}
\bibcite{huzaifah2017comparison}{31}
\bibcite{clemins2003application}{32}
\bibcite{cakir2017convolutional}{33}
\bibcite{le2011insect}{34}
\bibcite{rabiner1989tutorial}{35}
\bibcite{trifa2008automated}{36}
\bibcite{brown2009hidden}{37}
\bibcite{zhao2017automated}{38}
\bibcite{sercu2016very}{39}
\bibcite{takahashi2016deep}{40}
\bibcite{8081512}{41}
\bibcite{batdetect18}{42}
\bibcite{aide2013real}{43}
\bibcite{kim2002cepstrum}{44}
\bibcite{nicolson2019deep}{45}
\bibcite{sprengel2016audio}{46}
\bibcite{boll1979suppression}{47}
\bibcite{ephraim1985speech}{48}
\bibcite{schluter2015exploring}{49}
\bibcite{maas2013rectifier}{50}
\bibcite{simard2003best}{51}
\bibcite{kingma2014adam}{52}
\bibcite{ruder2016overview}{53}
\bibcite{felzenszwalb2009object}{54}
\bibcite{girshick2014rich}{55}
\bibcite{crump2017designing}{56}
\bibcite{hermans2017defense}{57}
\bibcite{park2019specaugment}{58}
\@writefile{toc}{\contentsline {chapter}{Appendix\ \numberline {A.}{\ }Baseline CNN Model}{66}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Structure of baseline model\relax }}{66}}
\newlabel{Fig:shapebaseline}{{A.1}{66}}
\@writefile{toc}{\contentsline {chapter}{Appendix\ \numberline {B.}{\ }VGG-based CNN Model}{67}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Structure of VGG-based model\relax }}{68}}
\newlabel{Fig:shapevgg}{{B.1}{68}}
